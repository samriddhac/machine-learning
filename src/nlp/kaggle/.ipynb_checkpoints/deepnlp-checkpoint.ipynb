{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Sheet_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = dataset.iloc[1:, 2] \n",
    "y_col = dataset.iloc[1:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(list(set(y_col)))\n",
    "y_int_to_label = {idx:label for idx,label in enumerate(set(y_col))}\n",
    "y_label_to_int = {label:idx for idx,label in enumerate(set(y_col))}\n",
    "y_int = np.array([y_label_to_int[label] for label in y_col])\n",
    "print(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_vect = vectorizer.fit_transform(x_col)\n",
    "y_vect = to_categorical(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_vect, y_vect, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 256)               168448    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 209,730\n",
      "Trainable params: 209,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='tanh', input_dim=x_vect.shape[1]))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41 samples, validate on 14 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 1.4256e-05 - acc: 1.0000 - val_loss: 1.5060 - val_acc: 0.6429\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.0108e-05 - acc: 1.0000 - val_loss: 1.5068 - val_acc: 0.6429\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1.0671e-05 - acc: 1.0000 - val_loss: 1.5074 - val_acc: 0.6429\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1.1078e-05 - acc: 1.0000 - val_loss: 1.5076 - val_acc: 0.6429\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1.0041e-05 - acc: 1.0000 - val_loss: 1.5079 - val_acc: 0.6429\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1.5489e-05 - acc: 1.0000 - val_loss: 1.5085 - val_acc: 0.6429\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1.1149e-05 - acc: 1.0000 - val_loss: 1.5091 - val_acc: 0.6429\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1.1007e-05 - acc: 1.0000 - val_loss: 1.5094 - val_acc: 0.6429\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1.6368e-05 - acc: 1.0000 - val_loss: 1.5098 - val_acc: 0.6429\n",
      "Epoch 10/50\n",
      " - 0s - loss: 2.3428e-05 - acc: 1.0000 - val_loss: 1.5107 - val_acc: 0.6429\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1.3679e-05 - acc: 1.0000 - val_loss: 1.5115 - val_acc: 0.6429\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1.6879e-05 - acc: 1.0000 - val_loss: 1.5125 - val_acc: 0.6429\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1.3544e-05 - acc: 1.0000 - val_loss: 1.5133 - val_acc: 0.6429\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1.2196e-05 - acc: 1.0000 - val_loss: 1.5141 - val_acc: 0.6429\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1.1069e-05 - acc: 1.0000 - val_loss: 1.5150 - val_acc: 0.6429\n",
      "Epoch 16/50\n",
      " - 0s - loss: 9.9832e-06 - acc: 1.0000 - val_loss: 1.5157 - val_acc: 0.6429\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1.0134e-05 - acc: 1.0000 - val_loss: 1.5164 - val_acc: 0.6429\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1.3356e-05 - acc: 1.0000 - val_loss: 1.5170 - val_acc: 0.6429\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1.6997e-05 - acc: 1.0000 - val_loss: 1.5179 - val_acc: 0.6429\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1.1908e-05 - acc: 1.0000 - val_loss: 1.5188 - val_acc: 0.6429\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1.3749e-05 - acc: 1.0000 - val_loss: 1.5195 - val_acc: 0.6429\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1.1925e-05 - acc: 1.0000 - val_loss: 1.5203 - val_acc: 0.6429\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1.1610e-05 - acc: 1.0000 - val_loss: 1.5216 - val_acc: 0.6429\n",
      "Epoch 24/50\n",
      " - 0s - loss: 9.5921e-06 - acc: 1.0000 - val_loss: 1.5227 - val_acc: 0.6429\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1.0450e-05 - acc: 1.0000 - val_loss: 1.5239 - val_acc: 0.6429\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1.3199e-05 - acc: 1.0000 - val_loss: 1.5248 - val_acc: 0.6429\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1.1614e-05 - acc: 1.0000 - val_loss: 1.5255 - val_acc: 0.6429\n",
      "Epoch 28/50\n",
      " - 0s - loss: 9.6183e-06 - acc: 1.0000 - val_loss: 1.5263 - val_acc: 0.6429\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1.5168e-05 - acc: 1.0000 - val_loss: 1.5275 - val_acc: 0.6429\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1.2469e-05 - acc: 1.0000 - val_loss: 1.5287 - val_acc: 0.6429\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1.4896e-05 - acc: 1.0000 - val_loss: 1.5295 - val_acc: 0.6429\n",
      "Epoch 32/50\n",
      " - 0s - loss: 8.3113e-06 - acc: 1.0000 - val_loss: 1.5303 - val_acc: 0.6429\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1.2056e-05 - acc: 1.0000 - val_loss: 1.5309 - val_acc: 0.6429\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1.7508e-05 - acc: 1.0000 - val_loss: 1.5314 - val_acc: 0.6429\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1.2298e-05 - acc: 1.0000 - val_loss: 1.5317 - val_acc: 0.6429\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1.0813e-05 - acc: 1.0000 - val_loss: 1.5323 - val_acc: 0.6429\n",
      "Epoch 37/50\n",
      " - 0s - loss: 9.2941e-06 - acc: 1.0000 - val_loss: 1.5331 - val_acc: 0.6429\n",
      "Epoch 38/50\n",
      " - 0s - loss: 6.4533e-06 - acc: 1.0000 - val_loss: 1.5337 - val_acc: 0.6429\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1.0718e-05 - acc: 1.0000 - val_loss: 1.5344 - val_acc: 0.6429\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1.3740e-05 - acc: 1.0000 - val_loss: 1.5353 - val_acc: 0.6429\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1.2113e-05 - acc: 1.0000 - val_loss: 1.5371 - val_acc: 0.6429\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1.2277e-05 - acc: 1.0000 - val_loss: 1.5388 - val_acc: 0.6429\n",
      "Epoch 43/50\n",
      " - 0s - loss: 8.9975e-06 - acc: 1.0000 - val_loss: 1.5403 - val_acc: 0.6429\n",
      "Epoch 44/50\n",
      " - 0s - loss: 7.7152e-06 - acc: 1.0000 - val_loss: 1.5414 - val_acc: 0.6429\n",
      "Epoch 45/50\n",
      " - 0s - loss: 9.2068e-06 - acc: 1.0000 - val_loss: 1.5419 - val_acc: 0.6429\n",
      "Epoch 46/50\n",
      " - 0s - loss: 1.1110e-05 - acc: 1.0000 - val_loss: 1.5422 - val_acc: 0.6429\n",
      "Epoch 47/50\n",
      " - 0s - loss: 1.1796e-05 - acc: 1.0000 - val_loss: 1.5428 - val_acc: 0.6429\n",
      "Epoch 48/50\n",
      " - 0s - loss: 1.0380e-05 - acc: 1.0000 - val_loss: 1.5437 - val_acc: 0.6429\n",
      "Epoch 49/50\n",
      " - 0s - loss: 1.3278e-05 - acc: 1.0000 - val_loss: 1.5445 - val_acc: 0.6429\n",
      "Epoch 50/50\n",
      " - 0s - loss: 9.2752e-06 - acc: 1.0000 - val_loss: 1.5450 - val_acc: 0.6429\n"
     ]
    }
   ],
   "source": [
    "num_epochs=50\n",
    "hist = model.fit(x_train, y_train, batch_size=10, epochs=num_epochs, verbose=2, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2760eb62ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss   = hist.history['val_loss']\n",
    "train_acc  = hist.history['acc']\n",
    "val_acc    = hist.history['val_acc']\n",
    "xc         = range(num_epochs)\n",
    "plt.figure()\n",
    "plt.plot(xc, train_loss, color='red')\n",
    "plt.plot(xc, val_loss, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 251us/step\n",
      "Accuracy  0.875\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Accuracy ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Sheet_2.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_col = dataset.iloc[1:, 2] \n",
    "y_col = dataset.iloc[1:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(list(set(y_col)))\n",
    "y_int_to_label = {idx:label for idx,label in enumerate(set(y_col))}\n",
    "y_label_to_int = {label:idx for idx,label in enumerate(set(y_col))}\n",
    "y_int = np.array([y_label_to_int[label] for label in y_col])\n",
    "print(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_vect = vectorizer.fit_transform(x_col)\n",
    "y_vect = to_categorical(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_vect, y_vect, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 256)               2929920   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,971,202\n",
      "Trainable params: 2,971,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='tanh', input_dim=x_vect.shape[1]))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 22 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6055 - acc: 0.7344 - val_loss: 0.6521 - val_acc: 0.6818\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.3684 - acc: 0.7656 - val_loss: 0.6220 - val_acc: 0.6818\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.1373 - acc: 0.9687 - val_loss: 0.5786 - val_acc: 0.7273\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.0261 - acc: 1.0000 - val_loss: 0.5886 - val_acc: 0.7273\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6683 - val_acc: 0.7273\n",
      "Epoch 6/50\n",
      " - 1s - loss: 9.6930e-04 - acc: 1.0000 - val_loss: 0.7470 - val_acc: 0.7273\n",
      "Epoch 7/50\n",
      " - 1s - loss: 2.7743e-04 - acc: 1.0000 - val_loss: 0.8050 - val_acc: 0.7273\n",
      "Epoch 8/50\n",
      " - 1s - loss: 1.7230e-04 - acc: 1.0000 - val_loss: 0.8401 - val_acc: 0.7273\n",
      "Epoch 9/50\n",
      " - 1s - loss: 1.2480e-04 - acc: 1.0000 - val_loss: 0.8605 - val_acc: 0.7273\n",
      "Epoch 10/50\n",
      " - 1s - loss: 1.0961e-04 - acc: 1.0000 - val_loss: 0.8730 - val_acc: 0.7273\n",
      "Epoch 11/50\n",
      " - 1s - loss: 8.9495e-05 - acc: 1.0000 - val_loss: 0.8813 - val_acc: 0.7273\n",
      "Epoch 12/50\n",
      " - 1s - loss: 8.8323e-05 - acc: 1.0000 - val_loss: 0.8886 - val_acc: 0.7273\n",
      "Epoch 13/50\n",
      " - 1s - loss: 1.0086e-04 - acc: 1.0000 - val_loss: 0.8936 - val_acc: 0.7273\n",
      "Epoch 14/50\n",
      " - 1s - loss: 7.9232e-05 - acc: 1.0000 - val_loss: 0.8983 - val_acc: 0.7273\n",
      "Epoch 15/50\n",
      " - 1s - loss: 8.0624e-05 - acc: 1.0000 - val_loss: 0.9018 - val_acc: 0.7273\n",
      "Epoch 16/50\n",
      " - 1s - loss: 7.6120e-05 - acc: 1.0000 - val_loss: 0.9053 - val_acc: 0.7273\n",
      "Epoch 17/50\n",
      " - 1s - loss: 1.0109e-04 - acc: 1.0000 - val_loss: 0.9092 - val_acc: 0.7273\n",
      "Epoch 18/50\n",
      " - 1s - loss: 9.3986e-05 - acc: 1.0000 - val_loss: 0.9140 - val_acc: 0.7273\n",
      "Epoch 19/50\n",
      " - 1s - loss: 6.8288e-05 - acc: 1.0000 - val_loss: 0.9190 - val_acc: 0.7273\n",
      "Epoch 20/50\n",
      " - 1s - loss: 8.1046e-05 - acc: 1.0000 - val_loss: 0.9234 - val_acc: 0.7273\n",
      "Epoch 21/50\n",
      " - 1s - loss: 6.8402e-05 - acc: 1.0000 - val_loss: 0.9277 - val_acc: 0.7273\n",
      "Epoch 22/50\n",
      " - 1s - loss: 6.9991e-05 - acc: 1.0000 - val_loss: 0.9322 - val_acc: 0.7273\n",
      "Epoch 23/50\n",
      " - 1s - loss: 5.7511e-05 - acc: 1.0000 - val_loss: 0.9374 - val_acc: 0.7273\n",
      "Epoch 24/50\n",
      " - 1s - loss: 5.7160e-05 - acc: 1.0000 - val_loss: 0.9424 - val_acc: 0.7273\n",
      "Epoch 25/50\n",
      " - 1s - loss: 5.4895e-05 - acc: 1.0000 - val_loss: 0.9463 - val_acc: 0.7273\n",
      "Epoch 26/50\n",
      " - 1s - loss: 7.8472e-05 - acc: 1.0000 - val_loss: 0.9504 - val_acc: 0.7273\n",
      "Epoch 27/50\n",
      " - 1s - loss: 7.1283e-05 - acc: 1.0000 - val_loss: 0.9548 - val_acc: 0.7273\n",
      "Epoch 28/50\n",
      " - 1s - loss: 5.4838e-05 - acc: 1.0000 - val_loss: 0.9589 - val_acc: 0.7273\n",
      "Epoch 29/50\n",
      " - 1s - loss: 5.2285e-05 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.7273\n",
      "Epoch 30/50\n",
      " - 1s - loss: 5.8642e-05 - acc: 1.0000 - val_loss: 0.9662 - val_acc: 0.7273\n",
      "Epoch 31/50\n",
      " - 1s - loss: 5.1162e-05 - acc: 1.0000 - val_loss: 0.9698 - val_acc: 0.7273\n",
      "Epoch 32/50\n",
      " - 1s - loss: 5.4694e-05 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.7273\n",
      "Epoch 33/50\n",
      " - 1s - loss: 4.7546e-05 - acc: 1.0000 - val_loss: 0.9773 - val_acc: 0.7273\n",
      "Epoch 34/50\n",
      " - 1s - loss: 4.7545e-05 - acc: 1.0000 - val_loss: 0.9813 - val_acc: 0.7273\n",
      "Epoch 35/50\n",
      " - 1s - loss: 5.2912e-05 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.7273\n",
      "Epoch 36/50\n",
      " - 1s - loss: 5.3873e-05 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.7273\n",
      "Epoch 37/50\n",
      " - 1s - loss: 5.5652e-05 - acc: 1.0000 - val_loss: 0.9926 - val_acc: 0.7273\n",
      "Epoch 38/50\n",
      " - 1s - loss: 5.2443e-05 - acc: 1.0000 - val_loss: 0.9971 - val_acc: 0.7273\n",
      "Epoch 39/50\n",
      " - 1s - loss: 6.2427e-05 - acc: 1.0000 - val_loss: 1.0021 - val_acc: 0.7273\n",
      "Epoch 40/50\n",
      " - 1s - loss: 6.7763e-05 - acc: 1.0000 - val_loss: 1.0089 - val_acc: 0.7273\n",
      "Epoch 41/50\n",
      " - 1s - loss: 4.2336e-05 - acc: 1.0000 - val_loss: 1.0137 - val_acc: 0.7273\n",
      "Epoch 42/50\n",
      " - 1s - loss: 3.7658e-05 - acc: 1.0000 - val_loss: 1.0175 - val_acc: 0.7273\n",
      "Epoch 43/50\n",
      " - 1s - loss: 4.2396e-05 - acc: 1.0000 - val_loss: 1.0218 - val_acc: 0.7273\n",
      "Epoch 44/50\n",
      " - 1s - loss: 4.5934e-05 - acc: 1.0000 - val_loss: 1.0256 - val_acc: 0.7273\n",
      "Epoch 45/50\n",
      " - 1s - loss: 3.5617e-05 - acc: 1.0000 - val_loss: 1.0293 - val_acc: 0.7273\n",
      "Epoch 46/50\n",
      " - 1s - loss: 2.9215e-05 - acc: 1.0000 - val_loss: 1.0325 - val_acc: 0.7273\n",
      "Epoch 47/50\n",
      " - 1s - loss: 3.6463e-05 - acc: 1.0000 - val_loss: 1.0360 - val_acc: 0.7273\n",
      "Epoch 48/50\n",
      " - 1s - loss: 3.7496e-05 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.7273\n",
      "Epoch 49/50\n",
      " - 1s - loss: 2.8889e-05 - acc: 1.0000 - val_loss: 1.0435 - val_acc: 0.7273\n",
      "Epoch 50/50\n",
      " - 1s - loss: 3.1876e-05 - acc: 1.0000 - val_loss: 1.0464 - val_acc: 0.7273\n"
     ]
    }
   ],
   "source": [
    "num_epochs=50\n",
    "hist = model.fit(x_train, y_train, batch_size=10, epochs=num_epochs, verbose=2, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2760cd08940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss   = hist.history['val_loss']\n",
    "train_acc  = hist.history['acc']\n",
    "val_acc    = hist.history['val_acc']\n",
    "xc         = range(num_epochs)\n",
    "plt.figure()\n",
    "plt.plot(xc, train_loss, color='red')\n",
    "plt.plot(xc, val_loss, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 633us/step\n",
      "Accuracy  0.7631578916\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Accuracy ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
