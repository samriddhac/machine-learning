{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('training.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "lines = [line.strip() for line in text.split('\\n')]\n",
    "for line in lines[1:]:\n",
    "    w = line.split('\\t')\n",
    "    if len(w) == 2:\n",
    "        train_x.append(w[0].strip().lower())\n",
    "        train_y.append(w[1].strip().lower())\n",
    "        x.append(w[0].strip().lower())\n",
    "        y.append(w[1].strip().lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calvin klein in2u eau de toilette  -  150 ml (for men)',\n",
       " 'for the love of physics (paperback)',\n",
       " 'nike fission deodorant spray  -  200 ml (for men)',\n",
       " 'spoken english (with cd) 2nd edition (paperback)',\n",
       " 'the c++ programming language 3 edition (paperback)',\n",
       " 'sony cybershot dsc-w610 point & shoot (black)',\n",
       " 'ibps bank probationary officers management trainees common written exam. 1st edition (paperback)',\n",
       " 'tommy hilfiger analog watch  - for women (silver)',\n",
       " \"dr. seuss's beginner book collection (boxed set)\",\n",
       " 'panasonic sdr-s15 camcorder (silver)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calvin klein',\n",
       " 'physics',\n",
       " 'nike-deodrant',\n",
       " 'spoken english',\n",
       " 'c programming',\n",
       " 'sony cybershot',\n",
       " 'written english',\n",
       " 'tommy watch',\n",
       " 'best-seller books',\n",
       " 'camcorder']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size :  88\n",
      "testing data size :  23\n"
     ]
    }
   ],
   "source": [
    "split = 0.8\n",
    "total = len(train_x)\n",
    "train_split = int(total*split)\n",
    "print('training data size : ', train_split)\n",
    "print('testing data size : ', (total-train_split))\n",
    "\n",
    "v_train_x = train_x[:train_split]\n",
    "v_train_y = train_y[:train_split]\n",
    "\n",
    "v_test_x = train_x[train_split:]\n",
    "v_test_y = train_y[train_split:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Performance\n",
    "\n",
    "## K-Fold Cross validation\n",
    "\n",
    "\n",
    "<b>Code Sample :</b>\n",
    "\n",
    "<code>\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(len(set(v_train_y)))\n",
    "accuracies = cross_val_score(estimator = nb_classifier, X=train_x, y=v_train_y, cv=4)\n",
    "print('All accuracies ', accuracies)\n",
    "print('Mean accuracies ', accuracies.mean())\n",
    "print('Std accuracies ', accuracies.std())\n",
    "</code>\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "<b>Code Sample (MultinomialNB) :</b>\n",
    "\n",
    "<code>\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    { 'alpha':[1.0, 0.0], 'fit_prior':[True, False] },\n",
    "    { 'alpha':[3.0, 2.0, 1.0, 0.0], 'fit_prior':[True, False] }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=parameters, scoring='accuracy', cv=8, n_jobs=-1)\n",
    "grid_search_result = grid_search.fit(train_x, v_train_y)\n",
    "\n",
    "print('Best accuracy ', grid_search_result.best_score_)\n",
    "print('Best params ', grid_search_result.best_params_)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.521739130435\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- sony cybershot\n",
      "chemistry ----------------- data structures algorithms\n",
      "sony cybershot ----------------- sony cybershot\n",
      "physics ----------------- written english\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- sony cybershot\n",
      "c programming ----------------- c programming\n",
      "camcorder ----------------- sony cybershot\n",
      "camera ----------------- camera\n",
      "physics ----------------- physics\n",
      "timex watch ----------------- tommy watch\n",
      "chemistry ----------------- data structures algorithms\n",
      "c programming ----------------- data structures algorithms\n",
      "mathematics ----------------- chemistry\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- data structures algorithms\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n",
      "20\n",
      "All accuracies  [ 0.85        0.68421053  0.73684211  0.92307692  0.77777778  0.8         1.\n",
      "  1.        ]\n",
      "Mean accuracies  0.846488416554\n",
      "Std accuracies  0.11081995254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Samriddha.Chatterjee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=8.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "D:\\Users\\Samriddha.Chatterjee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=8.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy  0.795454545455\n",
      "Best params  {'alpha': 1.0, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = MultinomialNB(alpha=1.0, fit_prior=False)\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(v_test_y, y_predict)\n",
    "#print(cm)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(len(set(v_train_y)))\n",
    "accuracies = cross_val_score(estimator = nb_classifier, X=train_x, y=v_train_y, cv=8)\n",
    "print('All accuracies ', accuracies)\n",
    "print('Mean accuracies ', accuracies.mean())\n",
    "print('Std accuracies ', accuracies.std())\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    { 'alpha':[1.0, 0.0], 'fit_prior':[True, False] },\n",
    "    { 'alpha':[3.0, 2.0, 1.0, 0.0], 'fit_prior':[True, False] }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=parameters, scoring='accuracy', cv=8, n_jobs=-1)\n",
    "grid_search_result = grid_search.fit(train_x, v_train_y)\n",
    "\n",
    "print('Best accuracy ', grid_search_result.best_score_)\n",
    "print('Best params ', grid_search_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.391304347826\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- sony cybershot\n",
      "chemistry ----------------- data structures algorithms\n",
      "sony cybershot ----------------- sony cybershot\n",
      "physics ----------------- written english\n",
      "spoken english ----------------- written english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- sony cybershot\n",
      "c programming ----------------- written english\n",
      "camcorder ----------------- sony cybershot\n",
      "camera ----------------- nike-deodrant\n",
      "physics ----------------- physics\n",
      "timex watch ----------------- tommy watch\n",
      "chemistry ----------------- data structures algorithms\n",
      "c programming ----------------- data structures algorithms\n",
      "mathematics ----------------- best-seller books\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- data structures algorithms\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "\n",
    "### Deriving Bayes Theorem from Conditional Probablity\n",
    "\n",
    "P(A|B) = P(A &#8745; B)|P(B) ==> P(A &#8745; B) = P(A|B) * P(B)\n",
    "P(B|A) = P(B &#8745; A)|P(A) ==> P(B &#8745; A) = P(B|A) * P(A)\n",
    "\n",
    "P(A &#8745; B) = P(B &#8745; A)\n",
    "\n",
    "So, P(A|B) * P(B) = P(B|A) * P(A)\n",
    "\n",
    "P(B|A) = P(A|B) * P(B) / P(A)\n",
    "\n",
    "<img src='./images/bayes_theorem.png'>\n",
    "<img src='./images/bayes_theorem_1.png'>\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
    "\n",
    "### Multinomial Naive Bayes\n",
    "\n",
    "With a multinomial event model, samples (feature vectors) represent the frequencies with which certain events have been generated by a multinomial \n",
    "( p 1 , … , p n ) where pi is the probability that event i occurs (or K such multinomials in the multiclass case). A feature vector x = ( x 1 , … , x n ) is then a histogram, with xi counting the number of times event i was observed in a particular instance. <b>This is the event model typically used for document classification</b>.\n",
    "\n",
    "the multinomial distribution is a generalization of the binomial distribution.\n",
    "For example, it models the probability of counts for rolling a k-sided die n times. For n independent trials each of which leads to a success for exactly one of k categories, with each category having a given fixed success probability, the multinomial distribution gives the probability of any particular combination of numbers of successes for the various categories.\n",
    "\n",
    "When k is 2 and n is 1, the multinomial distribution is the Bernoulli distribution. When k is 2 and n is bigger than 1, it is the binomial distribution. When n is 1, it is the categorical distribution.\n",
    "\n",
    "### Gaussian Naive Bayes\n",
    "\n",
    "When k is 2 and n is 1, the multinomial distribution is the Bernoulli distribution. When k is 2 and n is bigger than 1, it is the binomial distribution. When n is 1, it is the categorical distribution.\n",
    "\n",
    "\n",
    "### Bernoullis Naive Bayes\n",
    "\n",
    "In the multivariate Bernoulli event model, features are independent booleans (binary variables) describing inputs. Like the multinomial model, this model is popular for document classification tasks,[9] where binary term occurrence features are used rather than term frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.304347826087\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- sony cybershot\n",
      "chemistry ----------------- data structures algorithms\n",
      "sony cybershot ----------------- sony cybershot\n",
      "physics ----------------- written english\n",
      "spoken english ----------------- written english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- dslr canon\n",
      "c programming ----------------- written english\n",
      "camcorder ----------------- dslr canon\n",
      "camera ----------------- camera\n",
      "physics ----------------- best-seller books\n",
      "timex watch ----------------- tommy watch\n",
      "chemistry ----------------- data structures algorithms\n",
      "c programming ----------------- written english\n",
      "mathematics ----------------- written english\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- tommy watch\n",
      "c programming ----------------- written english\n",
      "spoken english ----------------- written english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(v_test_y, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.521739130435\n",
      "input ---------- Actual ----------------- Predicted\n",
      "calvin klein in2u eau de toilette  -  150 ml (for men) ---------- sony cybershot ----------------- camera\n",
      "for the love of physics (paperback) ---------- chemistry ----------------- mathematics\n",
      "nike fission deodorant spray  -  200 ml (for men) ---------- sony cybershot ----------------- camera\n",
      "spoken english (with cd) 2nd edition (paperback) ---------- physics ----------------- chemistry\n",
      "the c++ programming language 3 edition (paperback) ---------- spoken english ----------------- spoken english\n",
      "sony cybershot dsc-w610 point & shoot (black) ---------- written english ----------------- written english\n",
      "ibps bank probationary officers management trainees common written exam. 1st edition (paperback) ---------- camcorder ----------------- camcorder\n",
      "tommy hilfiger analog watch  - for women (silver) ---------- c programming ----------------- c programming\n",
      "dr. seuss's beginner book collection (boxed set) ---------- camcorder ----------------- camcorder\n",
      "panasonic sdr-s15 camcorder (silver) ---------- camera ----------------- camera\n",
      "study writing : a course in written english for academic purposes 2nd edition (paperback) ---------- physics ----------------- mathematics\n",
      "data structures and algorithms for gate: solutions to all previous gate questions since 1991 1st edition (paperback) ---------- timex watch ----------------- timex watch\n",
      "mathematics class-viii (paperback) ---------- chemistry ----------------- physics\n",
      "c in depth 3rd edition (paperback) ---------- c programming ----------------- data structures algorithms\n",
      "longman students grammar of spoken and written english 1st edition (paperback) ---------- mathematics ----------------- chemistry\n",
      "sony cybershot dsc-wx300 point & shoot (black) ---------- camera ----------------- camera\n",
      "titan octane analog watch  - for men (brown) ---------- sony cybershot ----------------- sony cybershot\n",
      "tommy hilfiger analog watch  - for men (black) ---------- titan watch ----------------- nike-deodrant\n",
      "practical everyday english: a self-study method of spoken english for upper intermediate and advanced students (paperback) ---------- c programming ----------------- physics\n",
      "case logic tbc-401 camera bag (black) ---------- spoken english ----------------- spoken english\n",
      "5 more combos ---------- best-seller books ----------------- physics\n",
      "dell meridian ii backpack - fits laptops of screen size... ---------- written english ----------------- written english\n",
      "nike basic purple deodorant spray  -  200 ml (for women) ---------- nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(train_x.toarray(), v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x.toarray())\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('input', '----------', 'Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_train_x[i], '----------', v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.217391304348\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- camera\n",
      "chemistry ----------------- written english\n",
      "sony cybershot ----------------- camera\n",
      "physics ----------------- written english\n",
      "spoken english ----------------- written english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camera\n",
      "c programming ----------------- written english\n",
      "camcorder ----------------- camera\n",
      "camera ----------------- camera\n",
      "physics ----------------- written english\n",
      "timex watch ----------------- tommy watch\n",
      "chemistry ----------------- written english\n",
      "c programming ----------------- written english\n",
      "mathematics ----------------- written english\n",
      "camera ----------------- camera\n",
      "sony cybershot ----------------- camera\n",
      "titan watch ----------------- tommy watch\n",
      "c programming ----------------- written english\n",
      "spoken english ----------------- written english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = BernoulliNB()\n",
    "nb_classifier.fit(train_x.toarray(), v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x.toarray())\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier\n",
    "\n",
    "<img src='./images/svm.png' width=\"600\" height=\"600\" />\n",
    "\n",
    "The goal of a support vector machine is to find  the optimal separating hyperplane which maximizes the margin of the training data.\n",
    "\n",
    "An hyperplane is a generalization of a plane\n",
    "\n",
    "in one dimension, an hyperplane is called a point\n",
    "in two dimensions, it is a line\n",
    "in three dimensions, it is a plane\n",
    "in more dimensions you can call it an hyperplane\n",
    "\n",
    "Objective is to select an hyperplane as far as possible from data points from each category. \n",
    "\n",
    "Given a particular hyperplane, we can compute the distance between the hyperplane and the closest data point. Once we have this value, if we double it we will get what is called the margin.  There will never be any data point inside the margin.\n",
    "The optimal hyperplane will be the one with the biggest margin.\n",
    "\n",
    "### Recap on vector\n",
    "\n",
    "https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-2/\n",
    "\n",
    "A vector is an object that has both a magnitude and a direction\n",
    "The magnitude or length of a vector x is written ∥x∥ and is called its norm.\n",
    "\n",
    "The direction of a vector u(u1,u2) is the vector w(u1/|u|, u2/|u|).\n",
    "<img src='https://i0.wp.com/www.svm-tutorial.com/wp-content/uploads/2014/11/03-unit-vector.png?resize=274%2C300&ssl=1!' width=\"250\" height=\"250\"/>\n",
    "We can see that w as indeed the same look as u except it is smaller. Something interesting about direction vectors like \n",
    "w is that their norm is equal to 1. That's why we often call them unit vectors.\n",
    "\n",
    "Given 2 vectors u=(u1, u2) and v =(v1,v2) . Sum of u and v :-\n",
    "u+v=(u1+v1, u2+v2)\n",
    "<img src='https://i2.wp.com/www.svm-tutorial.com/wp-content/uploads/2014/11/05-sum-of-two-vectors-e1415553207340.png?resize=420%2C261&ssl=1!' />\n",
    "\n",
    "u-v = (u1-v1, u2-v2)\n",
    "<img src='https://i1.wp.com/www.svm-tutorial.com/wp-content/uploads/2014/11/07-difference-of-two-vectors-2-e1415553244853.png?resize=450%2C239&ssl=1!' />\n",
    "v-u = (v1-u1, v2-u2)\n",
    "<img src='https://i1.wp.com/www.svm-tutorial.com/wp-content/uploads/2014/11/09-difference-of-two-vectors-4-e1415553260918.png?resize=320%2C288&ssl=1!' />\n",
    "\n",
    "However, since a vector has a magnitude and a direction, we often consider that parallel translate of a given vector (vectors with the same magnitude and direction but with a different origin) are the same vector, just drawn in a different place in space.\n",
    "\n",
    "Dot product :- \n",
    "\n",
    "Geometrically, it is the product of the Euclidian magnitudes of the two vectors and the cosine of the angle between them.<br>\n",
    "x.y=|x||y|cos&#920;\n",
    "<img src='./images/dot-product.png'>\n",
    "cos(theta) = cos(beta-alpha) = cos(beta)cos(alpha)-sin(beta)sin(alpha) \n",
    "\n",
    "==> (x1y1+x2y2)/|x|.|y|\n",
    "\n",
    "x.y = |x|.|y|.cos(theta) = x1y1+x2y2 (geometric definition of dot product)\n",
    "\n",
    "The orthogonal projection of a vector:-\n",
    "\n",
    "\n",
    "To project vector x onto y:-\n",
    "<img src='./images/dot-product-1.png' />\n",
    "z is the projection of x onto y.\n",
    "\n",
    "cos(theta) = |z|/|x|\n",
    "\n",
    "==> |z|=|x|.cos(theta) = |x|* x.y/|x|.|y| = x.y/|y|\n",
    "\n",
    "==> Say u=y/|y|, then |z|=x.u\n",
    "\n",
    "Now both y and z has same directon.\n",
    "\n",
    "then u = z/|z|, z= u.|z| = u(u.x) this is the orthogonal projection of x into y.\n",
    "\n",
    "\n",
    "## SVM Hyperplane\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.652173913043\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- camera\n",
      "chemistry ----------------- mathematics\n",
      "sony cybershot ----------------- camera\n",
      "physics ----------------- chemistry\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camcorder\n",
      "c programming ----------------- c programming\n",
      "camcorder ----------------- camcorder\n",
      "camera ----------------- camera\n",
      "physics ----------------- physics\n",
      "timex watch ----------------- timex watch\n",
      "chemistry ----------------- physics\n",
      "c programming ----------------- written english\n",
      "mathematics ----------------- chemistry\n",
      "camera ----------------- camera\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- c programming\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- physics\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Samriddha.Chatterjee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=8.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy  0.795454545455\n",
      "Best params  {'C': 1.9, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = SVC(kernel='linear', C=1.9, random_state=0)\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])\n",
    "    \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters =[\n",
    "    {'kernel':['linear'], 'C':[1.0, 1.9, 1.8, 1.7, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5] },\n",
    "    {'kernel':['rbf', 'poly', 'sigmoid'], 'C':[1.0, 10.0, 100.0], 'gamma':[0.1, 0.01, 0.001]}\n",
    "]\n",
    "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=parameters, scoring='accuracy', cv=8, n_jobs=-1)\n",
    "grid_search_result = grid_search.fit(train_x, v_train_y)\n",
    "\n",
    "print('Best accuracy ', grid_search_result.best_score_)\n",
    "print('Best params ', grid_search_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.608695652174\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- camera\n",
      "chemistry ----------------- mathematics\n",
      "sony cybershot ----------------- camera\n",
      "physics ----------------- chemistry\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camcorder\n",
      "c programming ----------------- c programming\n",
      "camcorder ----------------- camcorder\n",
      "camera ----------------- camera\n",
      "physics ----------------- physics\n",
      "timex watch ----------------- timex watch\n",
      "chemistry ----------------- data structures algorithms\n",
      "c programming ----------------- data structures algorithms\n",
      "mathematics ----------------- best-seller books\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- c programming\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- physics\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = LinearSVC(random_state=0)\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.739130434783\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- camera\n",
      "chemistry ----------------- written english\n",
      "sony cybershot ----------------- camera\n",
      "physics ----------------- chemistry\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camcorder\n",
      "c programming ----------------- c programming\n",
      "camcorder ----------------- camcorder\n",
      "camera ----------------- axe deo\n",
      "physics ----------------- physics\n",
      "timex watch ----------------- timex watch\n",
      "chemistry ----------------- chemistry\n",
      "c programming ----------------- c programming\n",
      "mathematics ----------------- mathematics\n",
      "camera ----------------- camera\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- c programming\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = DecisionTreeClassifier(random_state=0)\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.608695652174\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- camera\n",
      "chemistry ----------------- data structures algorithms\n",
      "sony cybershot ----------------- sony cybershot\n",
      "physics ----------------- written english\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camera\n",
      "c programming ----------------- c programming\n",
      "camcorder ----------------- camera\n",
      "camera ----------------- camera\n",
      "physics ----------------- physics\n",
      "timex watch ----------------- timex watch\n",
      "chemistry ----------------- data structures algorithms\n",
      "c programming ----------------- best-seller books\n",
      "mathematics ----------------- mathematics\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- c programming\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- c programming\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = RandomForestClassifier(random_state=0)\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.565217391304\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- sony cybershot\n",
      "chemistry ----------------- data structures algorithms\n",
      "sony cybershot ----------------- sony cybershot\n",
      "physics ----------------- written english\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camcorder\n",
      "c programming ----------------- written english\n",
      "camcorder ----------------- camcorder\n",
      "camera ----------------- camera\n",
      "physics ----------------- best-seller books\n",
      "timex watch ----------------- timex watch\n",
      "chemistry ----------------- data structures algorithms\n",
      "c programming ----------------- written english\n",
      "mathematics ----------------- best-seller books\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- data structures algorithms\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- written english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = LogisticRegression(random_state=0)\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.652173913043\n",
      "Actual ----------------- Predicted\n",
      "sony cybershot ----------------- sony cybershot\n",
      "chemistry ----------------- data structures algorithms\n",
      "sony cybershot ----------------- sony cybershot\n",
      "physics ----------------- best-seller books\n",
      "spoken english ----------------- spoken english\n",
      "written english ----------------- written english\n",
      "camcorder ----------------- camcorder\n",
      "c programming ----------------- c programming\n",
      "camcorder ----------------- camcorder\n",
      "camera ----------------- camera\n",
      "physics ----------------- best-seller books\n",
      "timex watch ----------------- timex watch\n",
      "chemistry ----------------- chemistry\n",
      "c programming ----------------- best-seller books\n",
      "mathematics ----------------- best-seller books\n",
      "camera ----------------- sony cybershot\n",
      "sony cybershot ----------------- sony cybershot\n",
      "titan watch ----------------- titan watch\n",
      "c programming ----------------- c programming\n",
      "spoken english ----------------- spoken english\n",
      "best-seller books ----------------- written english\n",
      "written english ----------------- spoken english\n",
      "nike-deodrant ----------------- nike-deodrant\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x = vectorizer.fit_transform(v_train_x)\n",
    "nb_classifier = KNeighborsClassifier()\n",
    "nb_classifier.fit(train_x, v_train_y)\n",
    "\n",
    "test_x = vectorizer.transform(v_test_x)\n",
    "y_predict = nb_classifier.predict(test_x)\n",
    "\n",
    "score = metrics.accuracy_score(v_test_y, y_predict)\n",
    "print('Accuracy ',score)\n",
    "\n",
    "print('Actual', '-----------------', 'Predicted')\n",
    "for i in range(len(v_test_y)):\n",
    "    print(v_test_y[i], '-----------------', y_predict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Net Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'dell laptops', 1: 'spoken english', 2: 'sony cybershot', 3: 'physics', 4: 'written english', 5: 'chromebook', 6: 'timex watch', 7: 'c programming', 8: 'nike-deodrant', 9: 'camcorder', 10: 'axe deo', 11: 'dslr canon', 12: 'chemistry', 13: 'mathematics', 14: 'tommy watch', 15: 'data structures algorithms', 16: 'calvin klein', 17: 'best-seller books', 18: 'camera', 19: 'titan watch'}\n",
      "{'dell laptops': 0, 'spoken english': 1, 'sony cybershot': 2, 'physics': 3, 'written english': 4, 'chromebook': 5, 'timex watch': 6, 'c programming': 7, 'nike-deodrant': 8, 'camcorder': 9, 'axe deo': 10, 'dslr canon': 11, 'chemistry': 12, 'mathematics': 13, 'tommy watch': 14, 'data structures algorithms': 15, 'calvin klein': 16, 'best-seller books': 17, 'camera': 18, 'titan watch': 19}\n",
      "[16, 3, 8, 1, 7, 2, 4, 14, 17, 9, 4, 15, 13, 7, 4, 2, 19, 14, 1, 18, 18, 0, 8, 9, 15, 10, 6, 3, 6, 19, 6, 8, 13, 14, 4, 15, 17, 17, 7, 10, 17, 0, 1, 2, 19, 1, 11, 9, 13, 0, 11, 11, 5, 11, 19, 17, 12, 14, 11, 14, 0, 16, 16, 14, 8, 11, 4, 10, 8, 15, 4, 18, 18, 13, 18, 2, 12, 11, 4, 16, 15, 4, 15, 0, 12, 13, 18, 3, 2, 12, 2, 3, 1, 4, 9, 7, 9, 18, 3, 6, 12, 7, 13, 18, 2, 19, 7, 1, 17, 4, 8]\n",
      "20\n",
      "(74, 338)\n",
      "(37, 338)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 128)               43392     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 20)                1300      \n",
      "=================================================================\n",
      "Total params: 52,948\n",
      "Trainable params: 52,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55 samples, validate on 19 samples\n",
      "Epoch 1/200\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 3.2452 - acc: 0.0000e+00 - val_loss: 2.8362 - val_acc: 0.1053\n",
      "Epoch 2/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 3.0972 - acc: 0.0364 - val_loss: 2.8633 - val_acc: 0.1579\n",
      "Epoch 3/200\n",
      "55/55 [==============================] - 0s 839us/step - loss: 3.0127 - acc: 0.0727 - val_loss: 2.8949 - val_acc: 0.1053\n",
      "Epoch 4/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 2.9406 - acc: 0.0909 - val_loss: 2.9356 - val_acc: 0.1053\n",
      "Epoch 5/200\n",
      "55/55 [==============================] - 0s 839us/step - loss: 2.9090 - acc: 0.0727 - val_loss: 2.9761 - val_acc: 0.1053\n",
      "Epoch 6/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.9091 - acc: 0.0727 - val_loss: 3.0087 - val_acc: 0.1053\n",
      "Epoch 7/200\n",
      "55/55 [==============================] - 0s 747us/step - loss: 2.8542 - acc: 0.0727 - val_loss: 3.0285 - val_acc: 0.1053\n",
      "Epoch 8/200\n",
      "55/55 [==============================] - 0s 784us/step - loss: 2.8391 - acc: 0.1091 - val_loss: 3.0534 - val_acc: 0.1053\n",
      "Epoch 9/200\n",
      "55/55 [==============================] - 0s 820us/step - loss: 2.8870 - acc: 0.0545 - val_loss: 3.0726 - val_acc: 0.1053\n",
      "Epoch 10/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 2.8392 - acc: 0.1455 - val_loss: 3.0882 - val_acc: 0.1053\n",
      "Epoch 11/200\n",
      "55/55 [==============================] - 0s 693us/step - loss: 2.8461 - acc: 0.0727 - val_loss: 3.1079 - val_acc: 0.1053\n",
      "Epoch 12/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 2.8698 - acc: 0.0909 - val_loss: 3.1196 - val_acc: 0.1053\n",
      "Epoch 13/200\n",
      "55/55 [==============================] - 0s 857us/step - loss: 2.8157 - acc: 0.1455 - val_loss: 3.1360 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "55/55 [==============================] - 0s 784us/step - loss: 2.8220 - acc: 0.1455 - val_loss: 3.1537 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 2.7839 - acc: 0.1455 - val_loss: 3.1713 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "55/55 [==============================] - 0s 784us/step - loss: 2.8308 - acc: 0.0909 - val_loss: 3.1828 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "55/55 [==============================] - 0s 711us/step - loss: 2.7941 - acc: 0.2000 - val_loss: 3.1907 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "55/55 [==============================] - 0s 912us/step - loss: 2.7958 - acc: 0.1273 - val_loss: 3.1965 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "55/55 [==============================] - 0s 784us/step - loss: 2.7897 - acc: 0.0909 - val_loss: 3.2028 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "55/55 [==============================] - 0s 802us/step - loss: 2.8132 - acc: 0.1273 - val_loss: 3.2011 - val_acc: 0.0526\n",
      "Epoch 21/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 2.7484 - acc: 0.1818 - val_loss: 3.2026 - val_acc: 0.1053\n",
      "Epoch 22/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.7339 - acc: 0.1818 - val_loss: 3.2119 - val_acc: 0.1053\n",
      "Epoch 23/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.7608 - acc: 0.0909 - val_loss: 3.2120 - val_acc: 0.1053\n",
      "Epoch 24/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 2.7871 - acc: 0.1091 - val_loss: 3.2187 - val_acc: 0.1579\n",
      "Epoch 25/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.6989 - acc: 0.1636 - val_loss: 3.2283 - val_acc: 0.1579\n",
      "Epoch 26/200\n",
      "55/55 [==============================] - 0s 893us/step - loss: 2.7576 - acc: 0.1455 - val_loss: 3.2329 - val_acc: 0.1579\n",
      "Epoch 27/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.6749 - acc: 0.1818 - val_loss: 3.2334 - val_acc: 0.1579\n",
      "Epoch 28/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.7073 - acc: 0.1455 - val_loss: 3.2374 - val_acc: 0.1579\n",
      "Epoch 29/200\n",
      "55/55 [==============================] - 0s 893us/step - loss: 2.7035 - acc: 0.1273 - val_loss: 3.2469 - val_acc: 0.1579\n",
      "Epoch 30/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 2.7468 - acc: 0.1455 - val_loss: 3.2481 - val_acc: 0.1579\n",
      "Epoch 31/200\n",
      "55/55 [==============================] - 0s 893us/step - loss: 2.6847 - acc: 0.2364 - val_loss: 3.2462 - val_acc: 0.1579\n",
      "Epoch 32/200\n",
      "55/55 [==============================] - 0s 820us/step - loss: 2.7123 - acc: 0.1455 - val_loss: 3.2579 - val_acc: 0.1579\n",
      "Epoch 33/200\n",
      "55/55 [==============================] - 0s 784us/step - loss: 2.6892 - acc: 0.2364 - val_loss: 3.2592 - val_acc: 0.2105\n",
      "Epoch 34/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.7176 - acc: 0.1636 - val_loss: 3.2607 - val_acc: 0.1579\n",
      "Epoch 35/200\n",
      "55/55 [==============================] - 0s 857us/step - loss: 2.6934 - acc: 0.2182 - val_loss: 3.2612 - val_acc: 0.2105\n",
      "Epoch 36/200\n",
      "55/55 [==============================] - 0s 693us/step - loss: 2.7093 - acc: 0.2182 - val_loss: 3.2577 - val_acc: 0.2105\n",
      "Epoch 37/200\n",
      "55/55 [==============================] - 0s 766us/step - loss: 2.6893 - acc: 0.2182 - val_loss: 3.2595 - val_acc: 0.2105\n",
      "Epoch 38/200\n",
      "55/55 [==============================] - 0s 729us/step - loss: 2.7274 - acc: 0.2000 - val_loss: 3.2668 - val_acc: 0.1579\n",
      "Epoch 39/200\n",
      "55/55 [==============================] - 0s 766us/step - loss: 2.6577 - acc: 0.1818 - val_loss: 3.2697 - val_acc: 0.1579\n",
      "Epoch 40/200\n",
      "55/55 [==============================] - 0s 839us/step - loss: 2.7152 - acc: 0.1455 - val_loss: 3.2648 - val_acc: 0.2105\n",
      "Epoch 41/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 2.6725 - acc: 0.1818 - val_loss: 3.2552 - val_acc: 0.2105\n",
      "Epoch 42/200\n",
      "55/55 [==============================] - 0s 875us/step - loss: 2.6362 - acc: 0.2182 - val_loss: 3.2483 - val_acc: 0.2105\n",
      "Epoch 43/200\n",
      "55/55 [==============================] - 0s 747us/step - loss: 2.6406 - acc: 0.2182 - val_loss: 3.2415 - val_acc: 0.2105\n",
      "Epoch 44/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.6029 - acc: 0.2545 - val_loss: 3.2351 - val_acc: 0.2632\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 675us/step - loss: 2.6416 - acc: 0.2545 - val_loss: 3.2349 - val_acc: 0.2105\n",
      "Epoch 46/200\n",
      "55/55 [==============================] - 0s 802us/step - loss: 2.5908 - acc: 0.2909 - val_loss: 3.2305 - val_acc: 0.2105\n",
      "Epoch 47/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 2.6333 - acc: 0.2182 - val_loss: 3.2320 - val_acc: 0.2105\n",
      "Epoch 48/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 2.5608 - acc: 0.2545 - val_loss: 3.2373 - val_acc: 0.2105\n",
      "Epoch 49/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 2.5718 - acc: 0.3091 - val_loss: 3.2284 - val_acc: 0.2632\n",
      "Epoch 50/200\n",
      "55/55 [==============================] - 0s 693us/step - loss: 2.6081 - acc: 0.2545 - val_loss: 3.2258 - val_acc: 0.2632\n",
      "Epoch 51/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 2.5696 - acc: 0.2182 - val_loss: 3.2243 - val_acc: 0.2105\n",
      "Epoch 52/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 2.5064 - acc: 0.3455 - val_loss: 3.2239 - val_acc: 0.2105\n",
      "Epoch 53/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 2.5740 - acc: 0.4000 - val_loss: 3.2231 - val_acc: 0.2105\n",
      "Epoch 54/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 2.5493 - acc: 0.3455 - val_loss: 3.2210 - val_acc: 0.2105\n",
      "Epoch 55/200\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.3637 - acc: 0.500 - 0s 474us/step - loss: 2.5080 - acc: 0.3636 - val_loss: 3.2188 - val_acc: 0.2105\n",
      "Epoch 56/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 2.4901 - acc: 0.3091 - val_loss: 3.2011 - val_acc: 0.2632\n",
      "Epoch 57/200\n",
      "55/55 [==============================] - 0s 711us/step - loss: 2.4951 - acc: 0.3273 - val_loss: 3.1893 - val_acc: 0.2632\n",
      "Epoch 58/200\n",
      "55/55 [==============================] - 0s 839us/step - loss: 2.4524 - acc: 0.3273 - val_loss: 3.1814 - val_acc: 0.2632\n",
      "Epoch 59/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 2.4921 - acc: 0.3636 - val_loss: 3.1742 - val_acc: 0.2632\n",
      "Epoch 60/200\n",
      "55/55 [==============================] - 0s 711us/step - loss: 2.4173 - acc: 0.3818 - val_loss: 3.1706 - val_acc: 0.2632\n",
      "Epoch 61/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 2.4464 - acc: 0.4182 - val_loss: 3.1584 - val_acc: 0.2632\n",
      "Epoch 62/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 2.3729 - acc: 0.4909 - val_loss: 3.1449 - val_acc: 0.2632\n",
      "Epoch 63/200\n",
      "55/55 [==============================] - 0s 619us/step - loss: 2.4240 - acc: 0.3091 - val_loss: 3.1277 - val_acc: 0.2632\n",
      "Epoch 64/200\n",
      "55/55 [==============================] - 0s 438us/step - loss: 2.4116 - acc: 0.3818 - val_loss: 3.1214 - val_acc: 0.2632\n",
      "Epoch 65/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 2.4382 - acc: 0.2909 - val_loss: 3.1213 - val_acc: 0.2632\n",
      "Epoch 66/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 2.3591 - acc: 0.4182 - val_loss: 3.1210 - val_acc: 0.2632\n",
      "Epoch 67/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.3613 - acc: 0.3818 - val_loss: 3.1163 - val_acc: 0.3684\n",
      "Epoch 68/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 2.3667 - acc: 0.4364 - val_loss: 3.1167 - val_acc: 0.3684\n",
      "Epoch 69/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.2898 - acc: 0.4909 - val_loss: 3.1022 - val_acc: 0.3684\n",
      "Epoch 70/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 2.2878 - acc: 0.4364 - val_loss: 3.1038 - val_acc: 0.3684\n",
      "Epoch 71/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 2.3040 - acc: 0.4364 - val_loss: 3.0870 - val_acc: 0.3684\n",
      "Epoch 72/200\n",
      "55/55 [==============================] - 0s 583us/step - loss: 2.2559 - acc: 0.4727 - val_loss: 3.0681 - val_acc: 0.3158\n",
      "Epoch 73/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 2.2333 - acc: 0.4364 - val_loss: 3.0612 - val_acc: 0.3158\n",
      "Epoch 74/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.1699 - acc: 0.4545 - val_loss: 3.0537 - val_acc: 0.3158\n",
      "Epoch 75/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 2.2341 - acc: 0.4364 - val_loss: 3.0502 - val_acc: 0.3158\n",
      "Epoch 76/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 2.1779 - acc: 0.4182 - val_loss: 3.0456 - val_acc: 0.3158\n",
      "Epoch 77/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.1656 - acc: 0.4909 - val_loss: 3.0415 - val_acc: 0.3158\n",
      "Epoch 78/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.0968 - acc: 0.5455 - val_loss: 3.0293 - val_acc: 0.3158\n",
      "Epoch 79/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 2.1686 - acc: 0.4182 - val_loss: 3.0076 - val_acc: 0.3158\n",
      "Epoch 80/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 2.1188 - acc: 0.5273 - val_loss: 3.0030 - val_acc: 0.3158\n",
      "Epoch 81/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 2.0156 - acc: 0.5273 - val_loss: 2.9940 - val_acc: 0.3158\n",
      "Epoch 82/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 2.0903 - acc: 0.4545 - val_loss: 2.9845 - val_acc: 0.3684\n",
      "Epoch 83/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 2.0414 - acc: 0.4909 - val_loss: 2.9767 - val_acc: 0.3684\n",
      "Epoch 84/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 2.0383 - acc: 0.5636 - val_loss: 2.9709 - val_acc: 0.3684\n",
      "Epoch 85/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 2.0293 - acc: 0.5273 - val_loss: 2.9610 - val_acc: 0.3684\n",
      "Epoch 86/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 1.9346 - acc: 0.5636 - val_loss: 2.9380 - val_acc: 0.3684\n",
      "Epoch 87/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 2.0096 - acc: 0.5091 - val_loss: 2.9232 - val_acc: 0.3158\n",
      "Epoch 88/200\n",
      "55/55 [==============================] - 0s 437us/step - loss: 1.9583 - acc: 0.4909 - val_loss: 2.9196 - val_acc: 0.3684\n",
      "Epoch 89/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 1.9205 - acc: 0.5818 - val_loss: 2.9201 - val_acc: 0.3684\n",
      "Epoch 90/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.8605 - acc: 0.5636 - val_loss: 2.9058 - val_acc: 0.3684\n",
      "Epoch 91/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 1.8432 - acc: 0.6364 - val_loss: 2.8938 - val_acc: 0.3684\n",
      "Epoch 92/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.8752 - acc: 0.5636 - val_loss: 2.8884 - val_acc: 0.3684\n",
      "Epoch 93/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 1.8058 - acc: 0.6182 - val_loss: 2.8755 - val_acc: 0.3684\n",
      "Epoch 94/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 1.8157 - acc: 0.5455 - val_loss: 2.8709 - val_acc: 0.3684\n",
      "Epoch 95/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 1.7755 - acc: 0.6727 - val_loss: 2.8562 - val_acc: 0.3684\n",
      "Epoch 96/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 1.7206 - acc: 0.6000 - val_loss: 2.8427 - val_acc: 0.3684\n",
      "Epoch 97/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 1.7202 - acc: 0.7091 - val_loss: 2.8337 - val_acc: 0.3684\n",
      "Epoch 98/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.7395 - acc: 0.6000 - val_loss: 2.8227 - val_acc: 0.3684\n",
      "Epoch 99/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.7070 - acc: 0.6000 - val_loss: 2.8169 - val_acc: 0.3684\n",
      "Epoch 100/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 1.6800 - acc: 0.6182 - val_loss: 2.8128 - val_acc: 0.3684\n",
      "Epoch 101/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.6494 - acc: 0.6000 - val_loss: 2.7985 - val_acc: 0.3684\n",
      "Epoch 102/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 1.6345 - acc: 0.6909 - val_loss: 2.7704 - val_acc: 0.3684\n",
      "Epoch 103/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.5763 - acc: 0.7273 - val_loss: 2.7579 - val_acc: 0.4211\n",
      "Epoch 104/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 1.5913 - acc: 0.6364 - val_loss: 2.7492 - val_acc: 0.4211\n",
      "Epoch 105/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.5480 - acc: 0.7273 - val_loss: 2.7400 - val_acc: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 1.4699 - acc: 0.7818 - val_loss: 2.7308 - val_acc: 0.4211\n",
      "Epoch 107/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.5328 - acc: 0.7455 - val_loss: 2.7225 - val_acc: 0.4737\n",
      "Epoch 108/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 1.5044 - acc: 0.7818 - val_loss: 2.7150 - val_acc: 0.4211\n",
      "Epoch 109/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 1.4796 - acc: 0.6727 - val_loss: 2.7021 - val_acc: 0.4211\n",
      "Epoch 110/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 1.4753 - acc: 0.7273 - val_loss: 2.6939 - val_acc: 0.4737\n",
      "Epoch 111/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 1.4867 - acc: 0.7091 - val_loss: 2.6807 - val_acc: 0.4737\n",
      "Epoch 112/200\n",
      "55/55 [==============================] - 0s 857us/step - loss: 1.4328 - acc: 0.7273 - val_loss: 2.6716 - val_acc: 0.5263\n",
      "Epoch 113/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.4575 - acc: 0.7455 - val_loss: 2.6586 - val_acc: 0.5263\n",
      "Epoch 114/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.4864 - acc: 0.7636 - val_loss: 2.6422 - val_acc: 0.5263\n",
      "Epoch 115/200\n",
      "55/55 [==============================] - 0s 674us/step - loss: 1.3937 - acc: 0.7636 - val_loss: 2.6349 - val_acc: 0.5263\n",
      "Epoch 116/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.3633 - acc: 0.7818 - val_loss: 2.6218 - val_acc: 0.5789\n",
      "Epoch 117/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 1.3678 - acc: 0.7273 - val_loss: 2.6167 - val_acc: 0.5789\n",
      "Epoch 118/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.3649 - acc: 0.7636 - val_loss: 2.6095 - val_acc: 0.5263\n",
      "Epoch 119/200\n",
      "55/55 [==============================] - 0s 711us/step - loss: 1.3437 - acc: 0.7818 - val_loss: 2.6051 - val_acc: 0.5263\n",
      "Epoch 120/200\n",
      "55/55 [==============================] - 0s 675us/step - loss: 1.3115 - acc: 0.7636 - val_loss: 2.5989 - val_acc: 0.5263\n",
      "Epoch 121/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.2048 - acc: 0.8545 - val_loss: 2.5847 - val_acc: 0.5263\n",
      "Epoch 122/200\n",
      "55/55 [==============================] - 0s 675us/step - loss: 1.3082 - acc: 0.8545 - val_loss: 2.5663 - val_acc: 0.5263\n",
      "Epoch 123/200\n",
      "55/55 [==============================] - 0s 638us/step - loss: 1.1788 - acc: 0.8000 - val_loss: 2.5492 - val_acc: 0.5789\n",
      "Epoch 124/200\n",
      "55/55 [==============================] - 0s 583us/step - loss: 1.2251 - acc: 0.8000 - val_loss: 2.5342 - val_acc: 0.5789\n",
      "Epoch 125/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 1.1483 - acc: 0.8364 - val_loss: 2.5233 - val_acc: 0.5789\n",
      "Epoch 126/200\n",
      "55/55 [==============================] - 0s 583us/step - loss: 1.1386 - acc: 0.8545 - val_loss: 2.5123 - val_acc: 0.5789\n",
      "Epoch 127/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 1.2270 - acc: 0.8000 - val_loss: 2.4971 - val_acc: 0.5263\n",
      "Epoch 128/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 1.1631 - acc: 0.8364 - val_loss: 2.4856 - val_acc: 0.5263\n",
      "Epoch 129/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.1050 - acc: 0.8545 - val_loss: 2.4777 - val_acc: 0.5263\n",
      "Epoch 130/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.0976 - acc: 0.8727 - val_loss: 2.4740 - val_acc: 0.5789\n",
      "Epoch 131/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 1.1043 - acc: 0.8909 - val_loss: 2.4653 - val_acc: 0.5789\n",
      "Epoch 132/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 1.1202 - acc: 0.8545 - val_loss: 2.4523 - val_acc: 0.5789\n",
      "Epoch 133/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 1.0028 - acc: 0.9091 - val_loss: 2.4481 - val_acc: 0.5789\n",
      "Epoch 134/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 1.0849 - acc: 0.9091 - val_loss: 2.4435 - val_acc: 0.5789\n",
      "Epoch 135/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 1.0207 - acc: 0.8364 - val_loss: 2.4362 - val_acc: 0.6316\n",
      "Epoch 136/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.9944 - acc: 0.8727 - val_loss: 2.4245 - val_acc: 0.6316\n",
      "Epoch 137/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 1.0293 - acc: 0.8545 - val_loss: 2.4167 - val_acc: 0.6316\n",
      "Epoch 138/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.0118 - acc: 0.8727 - val_loss: 2.4101 - val_acc: 0.6316\n",
      "Epoch 139/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 1.0061 - acc: 0.8727 - val_loss: 2.3973 - val_acc: 0.5789\n",
      "Epoch 140/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 1.0083 - acc: 0.8000 - val_loss: 2.3887 - val_acc: 0.5789\n",
      "Epoch 141/200\n",
      "55/55 [==============================] - 0s 547us/step - loss: 1.0159 - acc: 0.8364 - val_loss: 2.3731 - val_acc: 0.5789\n",
      "Epoch 142/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.9669 - acc: 0.8909 - val_loss: 2.3605 - val_acc: 0.6316\n",
      "Epoch 143/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 1.0043 - acc: 0.8364 - val_loss: 2.3538 - val_acc: 0.6842\n",
      "Epoch 144/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 0.9673 - acc: 0.8545 - val_loss: 2.3421 - val_acc: 0.6842\n",
      "Epoch 145/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.9298 - acc: 0.8545 - val_loss: 2.3310 - val_acc: 0.6842\n",
      "Epoch 146/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.8629 - acc: 0.8909 - val_loss: 2.3232 - val_acc: 0.6842\n",
      "Epoch 147/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.8808 - acc: 0.8727 - val_loss: 2.3140 - val_acc: 0.6842\n",
      "Epoch 148/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 0.8719 - acc: 0.8909 - val_loss: 2.3086 - val_acc: 0.6842\n",
      "Epoch 149/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 0.9197 - acc: 0.8727 - val_loss: 2.3039 - val_acc: 0.6842\n",
      "Epoch 150/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 0.8433 - acc: 0.8909 - val_loss: 2.2978 - val_acc: 0.6842\n",
      "Epoch 151/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.8389 - acc: 0.9455 - val_loss: 2.2918 - val_acc: 0.6842\n",
      "Epoch 152/200\n",
      "55/55 [==============================] - 0s 438us/step - loss: 0.8837 - acc: 0.8727 - val_loss: 2.2815 - val_acc: 0.6842\n",
      "Epoch 153/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.8272 - acc: 0.8364 - val_loss: 2.2828 - val_acc: 0.6842\n",
      "Epoch 154/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.8334 - acc: 0.8727 - val_loss: 2.2725 - val_acc: 0.6842\n",
      "Epoch 155/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.8319 - acc: 0.8727 - val_loss: 2.2644 - val_acc: 0.6842\n",
      "Epoch 156/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.8144 - acc: 0.8909 - val_loss: 2.2575 - val_acc: 0.6842\n",
      "Epoch 157/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.7751 - acc: 0.9091 - val_loss: 2.2565 - val_acc: 0.6842\n",
      "Epoch 158/200\n",
      "55/55 [==============================] - 0s 583us/step - loss: 0.7970 - acc: 0.9091 - val_loss: 2.2570 - val_acc: 0.6842\n",
      "Epoch 159/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.7319 - acc: 0.9273 - val_loss: 2.2472 - val_acc: 0.6842\n",
      "Epoch 160/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.7162 - acc: 0.9091 - val_loss: 2.2340 - val_acc: 0.6842\n",
      "Epoch 161/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.7018 - acc: 0.9273 - val_loss: 2.2237 - val_acc: 0.6842\n",
      "Epoch 162/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.7476 - acc: 0.9091 - val_loss: 2.2173 - val_acc: 0.7368\n",
      "Epoch 163/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.7275 - acc: 0.9273 - val_loss: 2.2059 - val_acc: 0.7368\n",
      "Epoch 164/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.7016 - acc: 0.9273 - val_loss: 2.1927 - val_acc: 0.7368\n",
      "Epoch 165/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.6783 - acc: 0.9455 - val_loss: 2.1831 - val_acc: 0.7368\n",
      "Epoch 166/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.6821 - acc: 0.9273 - val_loss: 2.1762 - val_acc: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.6511 - acc: 0.9455 - val_loss: 2.1709 - val_acc: 0.7368\n",
      "Epoch 168/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 0.6636 - acc: 0.9455 - val_loss: 2.1686 - val_acc: 0.7368\n",
      "Epoch 169/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.6322 - acc: 0.9273 - val_loss: 2.1656 - val_acc: 0.6842\n",
      "Epoch 170/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.6370 - acc: 0.9091 - val_loss: 2.1618 - val_acc: 0.6842\n",
      "Epoch 171/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.6976 - acc: 0.9091 - val_loss: 2.1555 - val_acc: 0.6842\n",
      "Epoch 172/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.6235 - acc: 0.9455 - val_loss: 2.1542 - val_acc: 0.7368\n",
      "Epoch 173/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.6198 - acc: 0.9455 - val_loss: 2.1519 - val_acc: 0.6842\n",
      "Epoch 174/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 0.6088 - acc: 0.9273 - val_loss: 2.1507 - val_acc: 0.6842\n",
      "Epoch 175/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.5887 - acc: 0.9455 - val_loss: 2.1419 - val_acc: 0.6842\n",
      "Epoch 176/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.5894 - acc: 0.8909 - val_loss: 2.1307 - val_acc: 0.7368\n",
      "Epoch 177/200\n",
      "55/55 [==============================] - 0s 529us/step - loss: 0.6253 - acc: 0.9636 - val_loss: 2.1223 - val_acc: 0.7368\n",
      "Epoch 178/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.5800 - acc: 0.9636 - val_loss: 2.1127 - val_acc: 0.7895\n",
      "Epoch 179/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.5623 - acc: 0.9818 - val_loss: 2.1124 - val_acc: 0.7895\n",
      "Epoch 180/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.5203 - acc: 0.9636 - val_loss: 2.1124 - val_acc: 0.7895\n",
      "Epoch 181/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.5750 - acc: 0.9636 - val_loss: 2.1066 - val_acc: 0.7368\n",
      "Epoch 182/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.5240 - acc: 0.9455 - val_loss: 2.1027 - val_acc: 0.7368\n",
      "Epoch 183/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.5257 - acc: 0.9455 - val_loss: 2.0972 - val_acc: 0.7368\n",
      "Epoch 184/200\n",
      "55/55 [==============================] - 0s 492us/step - loss: 0.5344 - acc: 0.9818 - val_loss: 2.0871 - val_acc: 0.7368\n",
      "Epoch 185/200\n",
      "55/55 [==============================] - 0s 565us/step - loss: 0.4748 - acc: 0.9818 - val_loss: 2.0786 - val_acc: 0.7368\n",
      "Epoch 186/200\n",
      "55/55 [==============================] - 0s 474us/step - loss: 0.5431 - acc: 0.9818 - val_loss: 2.0761 - val_acc: 0.7895\n",
      "Epoch 187/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.4817 - acc: 0.9455 - val_loss: 2.0757 - val_acc: 0.7895\n",
      "Epoch 188/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.4998 - acc: 0.9636 - val_loss: 2.0730 - val_acc: 0.7895\n",
      "Epoch 189/200\n",
      "55/55 [==============================] - 0s 456us/step - loss: 0.5251 - acc: 0.9091 - val_loss: 2.0697 - val_acc: 0.7368\n",
      "Epoch 190/200\n",
      "55/55 [==============================] - 0s 510us/step - loss: 0.5207 - acc: 0.9455 - val_loss: 2.0635 - val_acc: 0.7368\n",
      "Epoch 191/200\n",
      "55/55 [==============================] - 0s 693us/step - loss: 0.5064 - acc: 0.9455 - val_loss: 2.0504 - val_acc: 0.7895\n",
      "Epoch 192/200\n",
      "55/55 [==============================] - 0s 583us/step - loss: 0.4960 - acc: 0.9818 - val_loss: 2.0388 - val_acc: 0.7895\n",
      "Epoch 193/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 0.4638 - acc: 0.9455 - val_loss: 2.0328 - val_acc: 0.7368\n",
      "Epoch 194/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 0.4677 - acc: 0.9818 - val_loss: 2.0307 - val_acc: 0.7368\n",
      "Epoch 195/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 0.5071 - acc: 0.9273 - val_loss: 2.0276 - val_acc: 0.7368\n",
      "Epoch 196/200\n",
      "55/55 [==============================] - 0s 620us/step - loss: 0.4430 - acc: 0.9636 - val_loss: 2.0270 - val_acc: 0.7368\n",
      "Epoch 197/200\n",
      "55/55 [==============================] - 0s 602us/step - loss: 0.4637 - acc: 0.9455 - val_loss: 2.0222 - val_acc: 0.7368\n",
      "Epoch 198/200\n",
      "55/55 [==============================] - 0s 729us/step - loss: 0.4314 - acc: 0.9818 - val_loss: 2.0218 - val_acc: 0.7368\n",
      "Epoch 199/200\n",
      "55/55 [==============================] - 0s 656us/step - loss: 0.4106 - acc: 0.9818 - val_loss: 2.0223 - val_acc: 0.7368\n",
      "Epoch 200/200\n",
      "55/55 [==============================] - 0s 711us/step - loss: 0.4614 - acc: 0.9455 - val_loss: 2.0269 - val_acc: 0.7368\n",
      "37/37 [==============================] - 0s 298us/step\n",
      "accuracy  0.756756759979\n",
      " prediction  written english\n",
      " prediction  camera\n",
      " prediction  axe deo\n",
      " prediction  c programming\n",
      " prediction  axe deo\n",
      " prediction  data structures algorithms\n",
      " prediction  nike-deodrant\n",
      " prediction  data structures algorithms\n",
      " prediction  titan watch\n",
      " prediction  sony cybershot\n",
      " prediction  dslr canon\n",
      " prediction  c programming\n",
      " prediction  physics\n",
      " prediction  nike-deodrant\n",
      " prediction  tommy watch\n",
      " prediction  nike-deodrant\n",
      " prediction  written english\n",
      " prediction  c programming\n",
      " prediction  mathematics\n",
      " prediction  camera\n",
      " prediction  written english\n",
      " prediction  sony cybershot\n",
      " prediction  chemistry\n",
      " prediction  nike-deodrant\n",
      " prediction  written english\n",
      " prediction  camera\n",
      " prediction  titan watch\n",
      " prediction  sony cybershot\n",
      " prediction  dslr canon\n",
      " prediction  physics\n",
      " prediction  dslr canon\n",
      " prediction  dell laptops\n",
      " prediction  mathematics\n",
      " prediction  written english\n",
      " prediction  written english\n",
      " prediction  titan watch\n",
      " prediction  chemistry\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d85952438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_int_label = {idx:label for idx,label in enumerate(list(set(y)))}\n",
    "y_label_int = {label:idx for idx,label in enumerate(list(set(y)))}\n",
    "y_int = [y_label_int[label] for label in y]\n",
    "print(y_int_label)\n",
    "print(y_label_int)\n",
    "print(y_int)\n",
    "\n",
    "num_classes = len(set(y_int))\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_vect = vectorizer.fit_transform(x)\n",
    "y_vect = to_categorical(y_int)\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x_vect, y_vect, test_size=0.33)\n",
    "\n",
    "print(num_classes)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='sigmoid', input_dim=x_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "num_epochs = 200\n",
    "model_history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_split=0.25, verbose=1)\n",
    "\n",
    "train_loss = model_history.history['loss']\n",
    "val_loss   = model_history.history['val_loss']\n",
    "train_acc  = model_history.history['acc']\n",
    "val_acc    = model_history.history['val_acc']\n",
    "xc         = range(num_epochs)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('accuracy ',score[1])\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "for i,pred_y in enumerate(predictions):\n",
    "    max_pred = np.argmax(pred_y)\n",
    "    print(' prediction ', y_int_label[max_pred])\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(xc, train_loss, color='red')\n",
    "plt.plot(xc, val_loss, color='green')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
